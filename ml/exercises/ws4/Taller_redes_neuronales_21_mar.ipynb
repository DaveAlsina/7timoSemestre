{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Red neuronal para predicción de alquiler de bicicletas\n",
        "\n",
        "Construiremos una red neuronal, esta vez para un problema de regresión: predicción de la cantidad de bicicletas alquiladas, según el conjunto de datos *bikeshare_hour*, el cuál se proveerá. Adicionalmente, en esta ocasión encontraremos el mejor modelo usando un conjunto de validación.\n",
        "\n",
        "Cargar en formato .ipynb o .html en aulas a más tardar el día lunes 17 de marzo."
      ],
      "metadata": {
        "id": "MtJzIS1HeOsb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyuH3kGIVku9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data \n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar y preparar los datos\n",
        "\n",
        "Un paso muy importante en redes neuronales es preparar correctamente los datos. Variables con diferentes escalas le dificulta a la red aprender eficientemente los pesos correctos. \n"
      ],
      "metadata": {
        "id": "EdmFWlr2eN2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('bikeshare_hour.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "KooB2GeojdYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este dataset contiene el número de alquileres para cada hora de cada día desde Enero 1 de 2011 hasta Diciembre 31 de 2012. El número de usuarios que alquilaron se divide en regitrados *(registered)* y casuales *(casual)*, los cuales se suman en la columna *cnt*, la cuál será nuestra variable objetivo.\n",
        "\n",
        "\n",
        "Los fines de semana tienen un número más bajo de alquileres y hay picos cuando las personas se dirigen desde y hacia el trabajo durante la semana También tenemos información acerca de la temperatura, humedad, velocidad del viento, todas estas afectando el npumero de alquileres. Trataremos de capturar esta información con nuestro modelo.\n",
        "\n"
      ],
      "metadata": {
        "id": "nJbJ0xUkj0Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[:24*10].plot(x='dteday', y='cnt')"
      ],
      "metadata": {
        "id": "hKOhx_hRmUek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay algunas variables categóricas: **season**, **weathersit**, **mnth**, **hr**, **weekday**. Nevesitamos crear variables dummy para éstas. \n",
        "\n",
        "Así mismo, eliminaremos algunas variables que redundan o no aportan para el modelamiento el modelamiento: **instant**, **dteday**, **atemp**, **workingday**,**registered**, **casual** así como las **columnas originales de las variables que convertimos en dummies** si es necesario."
      ],
      "metadata": {
        "id": "9FPYGLaqmVdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO_DO1 Crear las variables dummies indicadas, y eliminar los atributos indicados"
      ],
      "metadata": {
        "id": "nNl0uDVTmsqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cambiar la escala en variables cuantitativas (normalizar).\n",
        "Para que el entrenamiento sea más fácil, estandarizaremos los datos de las variables contínuas, de manera que tengan media 0 y desviación estandar 1. \n",
        "\n",
        "Para esto, en las columnas de variables contínuas usamos la media y desviación estandar de la respectiva columna\n",
        "\n",
        "$$col:=\\frac{col-mean}{standardeviation}$$ "
      ],
      "metadata": {
        "id": "P9lXcUDhoI4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO_DO 2 Estandarizar las columnas cuantitativas: cnt, temp, hum, windspeed."
      ],
      "metadata": {
        "id": "-R8AjJzJoBGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Crear conjuntos de entrenamiento, validación y test\n",
        "\n",
        "En esta ocasión seleccionaremos los conjuntos de entrenamiento, vlaidación y test de forma ordenada. Para el test, seleccionaer los datos de aproximadamente los últimos 21 días. Para el conjunto de validación, tomar los datos de aproximadamente los últimos 60 días de los datos restantes."
      ],
      "metadata": {
        "id": "_5mCaI9Armma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO_DO3 Definir los conjuntos de train, test y validation. Darles los nombres train, val, test."
      ],
      "metadata": {
        "id": "UcA98WZnrlGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convertir los datos a tensores y prepararlos para alimentar la red\n",
        "A continuación  crearemos una clase (*MyDataset*) que nos prepara los datos para alimentar la red neuronal, convirtiendolos a parejas ordenadas de tensores conteniento los atributos y la variable objetivo. Sus parámetros son: el dataset df y el nombre de la columna objetivo en el dataset.\n"
      ],
      "metadata": {
        "id": "oe0XyxIFtS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset():\n",
        " \n",
        "  def __init__(self,df,target_column):\n",
        "    #price_df=pd.read_csv(file_name)\n",
        " \n",
        "    #x=price_df.iloc[:,0:8].values\n",
        "    #y=price_df.iloc[:,8].values\n",
        "    # y_train = df_train['activity']\n",
        "    # X_train = \n",
        "    y=df[target_column].values\n",
        "    X=df.drop(target_column,axis=1).values\n",
        "    self.X=torch.tensor(X,dtype=torch.float32)\n",
        "    self.y=torch.tensor(y,dtype=torch.float32)\n",
        " \n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "   \n",
        "  def __getitem__(self,idx):\n",
        "    return self.X[idx],self.y[idx]"
      ],
      "metadata": {
        "id": "ovRt0NLytnF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WUfPrPTbUQHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora usamos los Dataloaders para los conjuntos set, val y test."
      ],
      "metadata": {
        "id": "CB1Wuh0yuTe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar la clase MyDataset para preparar cada conjunto en forma de tensores\n",
        "train_sec=MyDataset(train,'cnt')\n",
        "test_sec=MyDataset(test,'cnt')\n",
        "val_sec=MyDataset(val,'cnt')"
      ],
      "metadata": {
        "id": "QZs4EuDTuVai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir los DataLoaders para cargar la información pro lotes\n",
        "train_data=DataLoader(\n",
        "    train_sec,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    #num_workers=0,\n",
        "    #collate_fn=None,\n",
        "    #pin_memory=False,\n",
        " )\n",
        "\n",
        "test_data=DataLoader(\n",
        "    test_sec,\n",
        "    batch_size=3,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    collate_fn=None,\n",
        "    pin_memory=False,\n",
        " )\n",
        "\n",
        "val_data=DataLoader(\n",
        "    val_sec,\n",
        "    batch_size=3,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    collate_fn=None,\n",
        "    pin_memory=False,\n",
        " )"
      ],
      "metadata": {
        "id": "yJjcOaN7ukXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a imprimir el primer bath del Test Set para visualizar y entender, sus tamaños y cómo el Dataloader ingresan los datos a la red neuronal."
      ],
      "metadata": {
        "id": "OLnxN2WNvPxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (data, labels) in enumerate(test_data):\n",
        "  print(data.shape, labels.shape)\n",
        "  print(data,labels)\n",
        "  break;"
      ],
      "metadata": {
        "id": "YN3DMvb9umEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definir la classe Net con la estructura de la red neuronal\n",
        "\n",
        "Basándose en el taller pasado, construya una red neuronal que tenga las siguientes características: \n",
        "- Una sola capa oculta. Usted decida el número de nodos. (Puede hacer entrenamientos pequeños, con una sola epoch por ejemplo, para hacer pruebas y decidir un buen número de nodos. Entre más nodos aprenderá más características de los datos, pero tardará más. Busque un buen equilibrio).\n",
        "- Una función de activación signoide para la capa oculta.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HbnK1f9asrEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO_DO 4 Escribir el código para la arquitectura de la red neuonal."
      ],
      "metadata": {
        "id": "u3Bru3KesqG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revisamos que estemos usando GPU y definimos el dispositivo "
      ],
      "metadata": {
        "id": "CzbRdjh-4r9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "wndN09Ya4qtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "id": "rtN8nDig4oQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el modelo, el optimizadoy y la función de costo."
      ],
      "metadata": {
        "id": "F5KvbK0L5BLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Net()\n",
        "\n",
        "#TO_DO 5 Definir el optimizador Stochastic gradient descent y la función MeanSquareError. Usar Learnig rate de 0.1\n",
        "optimizer=\n",
        "criterion="
      ],
      "metadata": {
        "id": "JUvzZYcs47NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenando la red y guardando el mejor modelo\n",
        "\n",
        "A continuación definimos la función de entrenamiento."
      ],
      "metadata": {
        "id": "s68IiHxyADx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pasamos el modelo al dispositivo GPU\n",
        "model.to(device)\n",
        "def train_model(model,optimizer,loss_module,train_loader,valid_loader,num_epochs):\n",
        "  \n",
        "  valid_loss_min =np.inf  #Vamos a encontrar el menor valor de error de validación. Por eso la inicializmaos como 'infinito'\n",
        "  \n",
        "  for i in range(num_epochs):\n",
        "    model.train()  #ponemos el modelo en modo entrenamiento. Es importante en otras arquitecturas como redes convolucionales.\n",
        "    train_loss = 0.0\n",
        "    v_loss = 0.0\n",
        "\n",
        "    # TODO 6 Completar el código a continuación\n",
        "    for data, target in train_loader:\n",
        "        # mover los tensores de atributos y etiquetas al dispositivo GPU\n",
        "\n",
        "        # Reiniciar los gradientes\n",
        "\n",
        "        # forward pass: calcular la salida para los datos de entrada..\n",
        "\n",
        "        # calculate the batch loss\n",
        "        \n",
        "        # backpropagation: cálculo de gradientes\n",
        "   \n",
        "        # actualizar los parámetros\n",
        "\n",
        "        # actualizar la cuenta de costos a lo largo de los lotes\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "    # for data,labels in testloader:\n",
        "\n",
        "    train_loss = train_loss/len(train_loader.dataset) \n",
        "\n",
        "    model.eval() #Ponemos el modelo en modo evaluación.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #for param in model.parameters():\n",
        "    #  print(param.data)\n",
        "    # vamos a evaluar el modelo entrenado, calculando predicciones con el conjunto de validación\n",
        "    for data,target in valid_loader:\n",
        "      data=data.to(device)\n",
        "      target=target.to(device)\n",
        "      output=model(data)\n",
        "      valid_loss= criterion(output, target)\n",
        "      valid_loss += loss.item()*data.size(0)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "    \n",
        "    #imprimir estadísticas de entrenamiento y validación\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        i, train_loss, valid_loss))\n",
        "    \n",
        "\n",
        "    #Guardamos el modelo con el menor error de validación.\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model_bikeshare.pt')\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y_Z3BWIs6DXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora entrene el modelo. Intente primero con una sola epoch para verificar que el codigo esté correcto. Luego de eso prube con más epochs. Con un buen rato de tiempo disponible podría intentar 100, 500, las que más quiera intentar de acuerdo a como vea su desempeño."
      ],
      "metadata": {
        "id": "nXpGJHcO8y4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model( )  #completar"
      ],
      "metadata": {
        "id": "nG7EhC099Rsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos el mejor modelo obtenido del entrenamiento. \n",
        "*Observación:* En el entrenamiento se guarda un modelo en un archivo .pt usted puede descargar el archivo y guardarlo localmente. De esta forma, si quiere usar el modelo nuevamente sin volver a realizar entrenamiento, sólo carguelo como se indica en la siguiente celda."
      ],
      "metadata": {
        "id": "cZeVo9TJ9dTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_bikeshare.pt'))"
      ],
      "metadata": {
        "id": "V35GtM169Wdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos los parámetros del modelo obtenido anteriormente"
      ],
      "metadata": {
        "id": "6yNPImH-9l3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print (name, param.data)"
      ],
      "metadata": {
        "id": "G5f-4tqI9ldc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación del modelo\n",
        "Ahora la prueba final con el test set. "
      ],
      "metadata": {
        "id": "j4QIP9as9u7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss=0.0\n",
        "\n",
        "criterion= nn.MSELoss()\n",
        "for data, target in test_data:\n",
        "  data=data.to(device)\n",
        "  target=target.to(device)\n",
        "  output=model(data)\n",
        "  loss= criterion(output,target)\n",
        "  test_loss += loss.item()*data.size(0)\n",
        "test_loss = test_loss/len(test_data.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n"
      ],
      "metadata": {
        "id": "kdELpZLp9uHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando el modelo en contexto"
      ],
      "metadata": {
        "id": "7fppYxUZAWq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO_DO 7: Finalmente, utilice el modelo encontrado para predecir el número de bicicletas rentadas en tres momentos (fecha, hora y demás atributos) diferentes que usted elija (pueden ser tomados del test set o con unos atributos nuevos que usted elija). \n",
        "Comente por favor lo siguiente: \n",
        "- Escribr si son atributos que usted seleccionó del dataset o unos nuevos.\n",
        "- Describa cómo obtuvo el valor de la predicción y qué valor dió (tenga en cuenta que la salida está normalizada, pero queremos la cantidad de bicicletas).\n",
        "- Si son atributos seleccionados del test set, compare su resultado con la etiqueta original. ¿Qué tal se desempeñó en esos tres casos?"
      ],
      "metadata": {
        "id": "zmSC3s4J96RC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vYyGLkXw944m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}